---
title: 概率论
date: 2021-12-17 14:00:00 +0800
categories: [Math, Probability and Statistical Analysis]
tags: [mathematics, probability, statistics, analysis]     # TAG names should always be lowercase
math: true
toc: true
---

> 本博客是基于中国科学技术大学的庄玮玮老师的 PPT 整理而成

# 事件与概率

# 随机变量及概率分布

# 随机变量的数字特征

## 随机变量的数学期望
<font color = yellow>定义 3.1.1</font> 设 $$X$$ 有概率分布 $$p_j=P(X=x_j), j = 0, 1, \cdots$$, 如果有 $$\displaystyle \sum^{\infty}_{j=0}|x_j|p_j<\infty$$, 则称 $$X$$ 的数学期望存在, 并且称 $$\displaystyle E(X) = \sum^{\infty}_{j=0}|x_j|p_j $$ 为 $$X$$ 或分布 $$\{p_j\}$$ 的**数学期望**.

<font color = yellow>定义 3.1.2</font> 设 $$X$$ 有概率密度 $$f(x)$$, 如果有 $$\displaystyle \int^\infty_{-\infty}xf(x)\mathrm{d}x<\infty$$, 则称 $$X$$ 的数学期望存在, 并且称 $$\displaystyle E(X) = \int^\infty_{-\infty}xf(x)\mathrm{d}x$$ 为 $$X$$ 或 $$f(x)$$ 的**数学期望**.

### 常用的数学期望
<font color=green>定理 3.1.1</font> 设 $$X$$ 的数学期望有限, 概率密度 $$f(x)$$ 关于 $$c$$ 对称 $$\Leftrightarrow\ f(c+x)=f(c-x)$$, 则 $$E(X) = c$$.

- 伯努利分布 $$B(1,p)$$ 与二项分布 $$B(n,p)$$

$$
X\sim B(1,p) \Rightarrow E(X)=p\quad X\sim B(n,p) \Rightarrow E(X)=np
$$

-  泊松分布 $$P(\lambda)$$

$$
X\sim P(\lambda) \Rightarrow E(X)=\lambda
$$

-  几何分布 $$P(X=j)=p(1-p)^{j-1}$$

$$
E(X)=\frac{1}{p}
$$

-  指数分布 $$\mathrm{Exp}(\lambda)$$

$$
E(X)=\frac{1}{\lambda}
$$

-  均匀分布 $$U(a,b)$$

$$
E(X)=\frac{a+b}{2}
$$

-  正态分布 $$N(\mu,\sigma^2)$$

$$
E(X)=μ
$$

### 数学期望的计算
<font color=green>定理 3.1.2</font> 设 $$X,Y$$ 为离散型随机变量, $$E(g(X)), E(h(X,Y))$$ 存在.
1. 若 $$X$$ 有离散分布 $$p_j=P(X=x_j), j\ge 1$$, 则 $$\displaystyle E(g(X)) = \sum^{\infty}_{j=1}g(x_j)p_j$$.
2. 若 $$X,Y$$ 有离散分布 $$p_{ij}=P(X=x_j, Y=y_j), i,j\ge 1$$, 则$$E(h(X,Y)) = \sum^{\infty}_{i,j=1}h(x_i,y_j)p_{ij} $$

> <font color = red>例 3.1.1</font> 
> $$\displaystyle X\sim B(n,p), E[X(X-1)] = \sum^n_{j=0}j(j-1)\mathrm{C}^j_np^j(1-p)^{n-j}=p^2\left.\left(\frac{\mathrm{d}^2}{\mathrm dx^2}\sum^n_{j=0}\mathrm{C}^j_nx^j(1-p)^{n-j}\right)\right|_{x=p}=p^2\left.\frac{\mathrm{d}^2}{\mathrm dx^2}(x+q)^n\right|_{x=p}=n(n-1)p^2$$

<font color=green>定理 3.1.3</font> 设 $$X,Y$$ 为连续型随机变量, $$E(g(X)), E(h(X,Y))$$ 存在.
1. 若 $$X$$ 有概率密度 $$f(x)$$, 则 $$\displaystyle E(g(X)) = \int_{-\infty}^\infty g(x)f(x)\mathrm{d}x$$.
2. 若 $$X,Y$$ 有概率密度 $$f(x,y)$$, 则 $$\displaystyle E(h(X,Y)) = \iint_{\mathbb{R}^2} h(x,y)f(x,y)\mathrm{d}x\mathrm{d}y$$.
3. 若 $$X$$ 是非负随机变量, 则 $$\displaystyle E(X) = \int_{0}^\infty P(X>x)\mathrm{d}x$$.

> <font color=red>例 3.1.2</font> $$\displaystyle X\sim U(0,\frac{\pi}{2}), E(\cos X) = \int_0^{\pi/2}\frac{2}{\pi}\cos x\mathrm dx=\frac{2}{\pi}$$

### 数学期望的性质
<font color=green>定理 3.1.4</font> 设 $$E(X_j)<\infty (1\le j\le n)$$, $$c_0, c_1, \cdots c_n$$ 是常数, 则有
1. 线性组合 $$Y = c_0 + c_1X_1 + c_2X_2 +\cdots + c_nX_n$$ 的数学期望存在, 而且有 $$E(Y) = c_0 + \sum^n_{j=1}c_jE(X_j)$$
2. 如果 $$X_1, X_2, \cdots, X_n$$ 相互独立, 则乘积 $$Z = X_1X_2\cdots X_n$$ 的数学期望存在, 而且有 $$E(Z) = \prod_{j=1}^nE(X_j)$$
3. 如果 $$P(X_1\le X_2) = 1$$, 则 $$E(X_1)\le E(X_2)$$

<font color=green>定理 3.1.5</font> $$E(|X|)=0$$ 的充分必要条件是 $$P(X=0)=1$$
此时我们称 $$X=0$$ **以概率 1 发生**, 记作 $$X=0\ a.s.$$ . 以概率 1 发生又被称作几乎处处或几乎必然 (almost surely) 发生.

## 随机变量的方差
<font color = yellow>定义 3.2.1</font> 设 $$\mu=E(X)$$, 如果 $$E\left((X-\mu)^2\right)<\infty$$ , 则称 $$\sigma^2=E\left((X-\mu)^2\right)$$ 为 $$X$$ 的**方差**, 记作 $$Var(X)$$ 或 $$\sigma_X^2$$. 称 $$\sigma_X=\sqrt{Var(X)}$$ 为 $$X$$ 的**标准差**.
- 当 $$X$$ 有离散分布 $$p_j=P(X=x_j), j=1,2,\cdots$$ 时, 有

$$
Var(X) = E\left((X-\mu)^2\right)=\sum^\infty_{j=1}(x_j-\mu)^2p_j
$$

- 当 $$X$$ 有概率密度 $$f(x)$$ 时, 有

$$
Var(X) = E\left((X-\mu)^2\right)=\int^\infty_{-\infty}(x-\mu)^2f(x)\mathrm dx
$$

说明随机变量 $$X$$ 的方差由 $$X$$ 的概率分布唯一决定, 即

<font color = green>定理 3.2.1</font> 如果 $$X,Y$$ 有相同的概率分布, 则它们有相同的数学期望和方差

> $$X$$ 的方差描述了 $$X$$ 的分散程度, $$Var(X)$$ 越小, 说明 $$X$$ 在数学期望附近越集中. 特别地, $$Var(X) = 0\Leftrightarrow X=\mu\ a.s.$$ 

利用方差的定义有

$$
Var(X)=E\left((X-\mu)^2\right)=E\left(X^2-2X\mu+\mu^2\right)=E\left(X^2\right)-E^2(X)
$$

这就是计算方差的常用公式.

### 常用的方差
- 伯努利分布 $$B(1,p)$$ 与二项分布 $$B(n,p)$$

$$
\begin{eqnarray}
&E(X) = np, E\left(X(X-1)\right)=n(n-1)p^2\Rightarrow E\left(X^2\right)=n(n-1)p^2+np\\
&Var(X)=n(n-1)p^2+np-(np)^2=np(1-p)
\end{eqnarray}
$$

- 泊松分布 $$P(\lambda)$$

$$
\begin{aligned}
E\left(X^2\right)&=E\left(X(X-1)\right)+E(X)\\
&=\sum_{k=0}^\infty k(k-1)\frac{\lambda^k}{k!}\exp(-\lambda)+\lambda\\
&=\lambda^2\sum_{k=2}^\infty \frac{\lambda^{k-2}}{(k-2)!}\exp(-\lambda)+\lambda\\
&=\lambda^2+\lambda
\end{aligned}
\Rightarrow Var(X)=\lambda^2+\lambda-\lambda^2
$$

- 几何分布 $$P(X=j)=p(1-p)^{j-1}$$

$$
\begin{eqnarray}
&\begin{aligned}
E\left(X^2\right)&=E\left(X(X-1)\right)+E(X)\\
&=\sum_{k=0}^\infty k(k-1)p(1-p)^{k-1}+\frac{1}{p}\\
&=p(1-p)\frac{\mathrm d^2}{\mathrm d(1-p)^2}\left(\sum_{k=0}^\infty(1-p)^k\right)+\frac{1}{p}\\
&=p(1-p)\frac{\mathrm d^2}{\mathrm d(1-p)^2}\left(\frac{1}{1-(1-p)}\right)+\frac{1}{p}\\
&=\frac{2p(1-p)}{p^3}+\frac{1}{p}\\
&=\frac{2(1-p)}{p^2}+\frac{1}{p}
\end{aligned}\\
&\Rightarrow Var(X)=\frac{2(1-p)}{p^2}+\frac{1}{p}-\frac{1}{p^2}=\frac{1-p}{p^2}
\end{eqnarray}
$$

- 指数分布 $$\mathrm{Exp}(\lambda)$$

$$
\begin{aligned}
E\left(X^2\right)&=\int^\infty_0x^2\lambda \exp(-\lambda x)\mathrm dx\\
&= \frac{1}{\lambda^2}\int^\infty_0t^2\exp(-t)\mathrm dt\\
&= \frac{1}{\lambda^2}\Gamma(3)\\
&= \frac{2}{\lambda^2}
\end{aligned}
\Rightarrow Var(X)=\frac{2}{\lambda^2}-\frac{1}{\lambda^2}=\frac{1}{\lambda^2}
$$

- 均匀分布 $$U(a,b)$$

$$
E\left(X^2\right)=\int_a^b\frac{x^2}{b-a}\mathrm dx=\frac{b^3-a^3}{3(b-a)}\Rightarrow Var(x)=\frac{b^3-a^3}{3(b-1)}-\left(\frac{a+b}{12}\right)^2=\frac{(b-a)^2}{12}
$$

- 正态分布 $$N(\mu,\sigma^2)$$

$$
Var(X)=\sigma^2
$$

### 方差的性质
<font color=green>定理 3.2.2</font> 设 $$a,b,c$$ 是常数, $$E(X)=\mu, Var(X)<\infty$$,  $$E(X_j)=\mu_j, Var(X_j)<\infty (1\le j\le n)$$, 则有
1. $$Var(a+bX)=b^2Var(X)$$
2. $$\forall c\neq \mu, Var(X)=E\left((X-\mu)^2\right) <E\left((X-c)^2\right)$$ 
3. $$Var(X)=0\Leftrightarrow P(X=\mu)=1$$
4. 当 $$X_1, X_2, \cdots, X_n$$ 相互独立时, $$Var\left(\sum_{j=1}^nX_j\right)=\sum_{j=1}^nVar(X_j)$$

设 $$X\sim N(\mu,\sigma^2), Y=\frac{X-\mu}{\sigma}$$, 则 $$E(Y)=0, Var(Y)=1$$, 这时称 $$Y$$ 为 $$X$$ 的**标准化**.

## 协方差和相关系数
### 内积不等式
<font color=green>定理 3.3.1</font> 设 $$E\left(X^2\right)<\infty,E\left(Y^2\right)<\infty$$, 则有 $$|E(XY)|\le \sqrt{E\left(X^2\right)E\left(Y^2\right)}$$, 其中等号成立的充分必要条件是有不全为零的常数 $$a,b$$ 使得 $$P(aX+bY=0)=1$$
### 协方差和相关系数
<font color = yellow>定义 3.3.1</font> 设 $$\mu_X=E(X), \mu_Y=E(Y), \sigma_X=\sqrt{Var(X)}, \sigma_Y=\sqrt{Var(Y)}$$.
1. 当 $$\sigma_X,\sigma_Y$$ 存在时, 称 $$E((X-\mu_X)(Y-\mu_Y))$$ 为随机变量 $$X,Y$$ 的**协方差**, 记作 $$Cov(X,Y)$$, 或 $$\sigma_{XY}$$. 当 $$Cov(X,Y)=0$$ 时, 称 $$X,Y$$ **不相关**.
2. 当 $$0<\sigma_X\sigma_Y<\infty$$ 时, 称 $$\rho_{XY}=\frac{\sigma_{XY}}{\sigma_X\sigma_Y}$$ 为 $$X,Y$$ 的**相关系数**, $$\rho_{XY}$$ 也常用 $$\rho(X,Y)$$ 表示.

类似计算方差的常用公式, 我们有以下计算协方差的常用公式:

$$
Cov(X,Y)=E(XY)-E(X)E(Y)
$$

利用内积不等式和相关系数的定义, 我们有以下性质

<font color=green>定理 3.3.2</font> 设 $$\rho_{XY}$$ 是 $$X,Y$$ 的相关系数, 则有
1. $$|\rho_{XY}|\le 1$$
2. $$|\rho_{XY}|= 1\Leftrightarrow \exists a,b, s.t.\ P(Y=a+bX)=1$$
3. 如果 $$X,Y$$ 独立, 则 $$X,Y$$ 不相关.

- 可以看出, $$\lvert\rho_{XY}\rvert= 1$$ 时, $$X,Y$$ 有线性关系, 这时称 $$X,Y$$ **线性相关**.
- 相关系数只表示了随机变量之间的线性关系, 相关系数为零时两随机变量之间也可以有其他非线性关系, 比如 $$X\sim N(0,1), Cov\left(X,X^2\right)=E\left(X^3\right)-E(X)=0\Rightarrow\rho\left(X,X^2\right)=0$$.

### 协方差矩阵
<font color = yellow>定义 3.3.1</font> 称随机向量 $$(X_1,X_2)$$ 的协方差 $$\sigma_{ij}=Cov(X_i,X_j)$$ 构成的矩阵

$$
\Sigma=\left(
\begin{matrix}
\sigma_{11}&\sigma_{12}\\
\sigma_{21}&\sigma_{22}
\end{matrix}
\right)
$$

为 $$X$$ 的**协方差矩阵**. 因为 $$\sigma_{12}=\sigma_{21}$$, 所以协方差矩阵 $$\Sigma$$ 是对称矩阵.

<font color=green>定理 3.3.3</font> 设 $$\boldsymbol X=(X_1, X_2)$$ 有协方差矩阵 $$\Sigma$$, $$E(\boldsymbol X)=(\mu_1,\mu_2)$$, 则
1. $$\Sigma$$ 是正半定矩阵
2. $$\Sigma$$ 退化的充分必要条件是有不全为零的常数 $$a_1, a_2$$ 使得

$$
P\left(\sum_{i=1}^2a_i(X_i-\mu_i)=0\right)=1
$$

## 正态分布的参数计算
设 $$Y_1, Y_2\sim N(0,1)$$ 独立, $$ac-bd\neq0$$ 且

$$
\begin{cases}
X_1=aY_1+bY_2+\mu_1\\
X_2=cY_1+dY_2+\mu_2
\end{cases}
$$

则 
$$
Cov(X_1,X_2)=ac+bd,(X_1,X_2)\sim N(\mu_1, \mu_2;\sigma_1^2, \sigma_2^2; \rho)
$$

其中有

$$
\sigma_1^2=a^2+b^2, \sigma_2^2=c^2+d^2, \rho=\frac{ac+bd}{\sigma_1\sigma_2}
$$

容易计算得到 $$X_1, X_2$$ 的数字特征

$$
\begin{cases}
E(X_1)=\mu_1 & E(X_2) = \mu_2\\
Var(X_1)=\sigma_1^2 & Var(X_2)= \sigma_2^2\\
\rho_{X_1X_2}=\rho
\end{cases}
$$

<font color=green>定理 3.4.1</font> 如果 $$(X_1,X_2)\sim N(\mu_1, \mu_2;\sigma_1^2, \sigma_2^2; \rho)$$, 则 $$X_1, X_2$$ 的数字特征如上式, 且 $$X_1, X_2$$ 独立的充分必要条件是 $$X_1, X_2$$ 不相关

# 大数定律和中心极限定理

## 强大数律

<font color = yellow>定义 4.1.1</font> 我们用 $$A\ a.s.$$ 表示 $$P(A)=1$$, 即

$$
P(A)=1\Leftrightarrow A\ a.s.
$$

<font color=green>定理 4.1.1</font> (强大数律) 如果 $$X_1,X_2. \cdots$$ 是独立同分布的随机变量, $$\mu=E(X_1)$$, 则

$$
\overline{X_n}=\frac{1}{n}\sum^n_{j=1}X_j, \lim_{n\to\infty}\overline{X_n}=\mu\ a.s.
$$

因为概率等于 1 的事件在实际中必然发生, 所以在强大数律中, 如果用 $$x_n$$ 表示 $$X_n$$ 的观测值, 则有

$$
\lim_{n\to\infty}\frac{x_1+x_2+\cdots+x_n}{n}=\mu
$$

> 因为强大数律的数学证明不需要概率的频率定义, 所以它从理论上保证了概率的频率定义是正确的.

## 弱大数律

有强大数律, 自然就有弱大数律. 为了介绍弱大数律, 先介绍随机变量的**依概率收敛**和**切比雪夫不等式**.

<font color = yellow>定义 4.2.1</font> 设 $$U, U_1, U_2, \cdots$$ 是随机变量. 若 $$\forall\varepsilon>0, \lim_{n\to\infty}P(\lvert U_n-U\rvert\ge\varepsilon)=0$$, 则称 $$U_n$$ 依概率收敛到 $$U$$, 记作 $$U_n\xrightarrow{P}U$$.

<font color=green>引理 4.2.1</font> (**切比雪夫不等式**) 设随机变量 $$X$$ 有数学期望 $$\mu$$ 和方差 $$\sigma^2$$, 则对常数 $$\varepsilon>0$$, 有

$$
P(\lvert X-\mu\rvert\ge\varepsilon)\le\frac{\sigma^2}{\varepsilon^2}
$$

---

**证明:** 记 $$I[A]$$ 为事件 $$A$$ 的示性函数, $$Y=\lvert X-\mu\rvert$$, 则无论 $$\{Y\ge\varepsilon\}$$ 是否发生, 总有

$$
I[\{Y\ge\varepsilon\}]\le\frac{Y^2}{\varepsilon^2}
$$

因此

$$
\begin{aligned}
P(\lvert X-\mu\rvert\ge\varepsilon)&=P(Y\ge\varepsilon)=E(I[\{Y\ge\varepsilon\}])\\
&\le E\left(\frac{Y^2}{\varepsilon^2}\right)=\frac{E(Y^2)}{\varepsilon^2}=\frac{\sigma^2}{\varepsilon^2}
\end{aligned}
$$

---

> 切比雪夫不等式是概率论中最重要和最基本的不等式.

<font color=green>推论 4.2.2</font> (**弱大数律**) 设随机变量 $$X_1, X_2, \cdots$$ 独立同分布, $$\mu=E(X_1)$$, 则对任何 $$\varepsilon>0$$, 有

$$
\lim_{n\to\infty} P\left(\lvert\overline{X_n}-\mu\rvert\ge\varepsilon\right)=0
$$

## 中心极限定理

> 强大数律和弱大数律分别讨论了随机变量的样本均值的几乎处处收敛和依概率收敛. 中心极限定律研究当 $$n$$ 比较大时, 随机变量的部分和 $$S_n=\sum^n_{j=1}X_j$$ 的概率分布问题.

独立同分布随机变量和的分布近似于正态分布.

<font color=green>定理 4.3.1</font> (**中心极限定理**) 设随机变量 $$X_1, X_2, \cdots$$ 独立同分布, $$E(X_1)=\mu, Var(X_1)=\sigma^2>0$$. 记 $$S_n=\sum^n_{j=1}X_j$$ 为部分和, $$Z_n=\frac{S_n-n\mu}{\sqrt{n\sigma^2}}$$ 为 $$S_n$$ 的标准化, $$\Phi(x)$$ 表示服从 $$N(0,1)$$ 的分布函数. 当 $$n\to\infty$$ 时, 有

$$
P(Z_n\le x)\to\Phi(x), x\in\mathbb R
$$

称 $$Z_n$$ 依概率收敛到 $$N(0,1)$$, 记作 $$Z_n\xrightarrow d N(0,1)$$.

注意, 样本均值 $$\overline{X_n}$$ 的标准化等于部分和 $$S_n$$ 的标准化:

$$
Z_n=\frac{S_n-n\mu}{\sqrt{n\sigma^2}}=\frac{\overline{X_n}-\mu}{\sqrt{\sigma^2/n}}
$$

<font color=green>推论 4.3.2</font> 在定理 4.3.1 的条件下, 对较大的 $$n$$, 有

$$
\begin{eqnarray}
P\left(\frac{S_n-n\mu}{\sqrt{n\sigma^2}}\le x\right)\approx\Phi(x)\\
P\left(\frac{\overline{X_n}-\mu}{\sqrt{\sigma^2/n}}\le x\right)\approx\Phi(x)
\end{eqnarray}
$$

其中不知道方差时, 可以用样本方差

$$
\hat\sigma^2=\frac{1}{n-1}\sum^n_{j=1}\left(X_j-\overline{X_n}\right)^2\quad\mathrm{或}\quad\hat\sigma^2=\frac{1}{n}\sum^n_{j=1}\left(X_j-\overline{X_n}\right)^2
$$

代替 $$\sigma^2$$.

